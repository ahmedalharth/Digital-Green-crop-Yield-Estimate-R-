---
title: "Crop Yield Analysis"
author: "Ahemd Elharith Osama"
date: "`r Sys.Date()`"
output:
  word_document:
    reference_docx: "tamplet.docx"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

> # Introduction

Smallholder farmers are crucial contributors to global food production, and in India often suffer most from poverty and malnutrition. These farmers face challenges such as limited access to modern agriculture, unpredictable weather, and resource constraints. To tackle this issue, Digital Green collected data via surveys, offering insights into farming practices, environmental conditions, and crop yields.

> # About the Data

The data was collected through a survey conducted across multiple districts in India. It consists of a variety of factors that could potentially impact the yield of rice crops. These factors include things like the type and amount of fertilizers used, the quantity of seedlings planted, methods of preparing the land, different irrigation techniques employed, among other features. The dataset comprises more than 5000 data points, each having more than 40 features.

-   ***Data source : [Zindi platform](https://zindi.africa/competitions/digital-green-crop-yield-estimate-challenge/data) .***

-   ***Data files : [Train.csv](https://docs.google.com/spreadsheets/d/1aZwFRA2Cm2s2s7OxFwlU-D8s4vmDUO3OCjYgDq7U95A/edit?usp=sharing) and [VariableDescription.csv](https://docs.google.com/spreadsheets/d/1IDrSq9wI5BsXIgRMiOGFoOJNM914XB9xxOpepNQ53q8/edit?usp=sharing) .***

-   ***powered by : [Digital Green](https://www.digitalgreen.org/) and [Fair Forward AI](https://www.bmz-digital.global/en/overview-of-initiatives/fair-forward/) .***

> # The objective

The most important variable in this data is the Yield variable which is the corp yield for different farmers in India (wheat and rice crops) , we want to answer the following questions :

1.  What the distribution of the yield variables ?

2.  what is the crop yield for each District in India what is the largest ?

3.  What is the different agriculture methods that influence the crop yield ?

4.  What the best agriculture methods that implies better crop yield ?

5.  What are the variables that are correlated to the yield variable ?

> ***NOTE :***
>
> ***We gonna use statistical inference with proper tests to draw conclusion about these questions and estimate the population parameters.***

# Workflow Description:

**We'll go through the following steps in order to achieve the objective** :

1.  Discovering the data.

2.  Explanatory Data Analysis "EDA".

3.  Cleaning the data.

4.  Data analysis and visualization.

5.  Statistical testing

6.  Insights and conclusion(Report.pdf).

> # 1. Discovering the data:

*`The data files are as follows :`*

-   *`"Train.csv" : containing the data under study.`*

-   *`"VariableDescription.csv" : containing the definitions of each variables or features in the Train.csv.`*

-   *`"Test.csv" : containing the data without the "Yield" variable , so we'll not use this file.`*

> ## 1.1 Importing libraries

```{r}
library(psych)
library(vcd)
library(pander)
library(knitr)
library(kableExtra)
library(ggplot2)
library(dplyr)
options(repr.plot.width = 12, repr.plot.height = 8)
```

> ## 1.2 Load the data

```{r}
train_df <- read.csv("Train.csv")
variable_defintion <- read.csv("VariableDescription.csv")
```

-   Data shape

    ```{r echo=FALSE, paged.print=TRUE}
    pander(paste("Number of rows :" , nrow(train_df)))
    pander(paste("\nNumber of Variables :" , ncol(train_df)))

    ```

> ## 1.3 Data types

*`We Have three types of features (Numeric, Categorical and Date time) , we'll explore each of them individually  for easier analysis letter.`*

-   ***Date time features***

    ```{r}
    date_time <- c("CropTillageDate" ,"RcNursEstDate" ,"Harv_date" , "Threshing_date" ,
                       "SeedingSowingTransplanting")
    pander(colnames(train_df[,date_time]) , style = "rmarkdown")
    ```

    ```{r}
    pander(paste("Number of date time features " , length(date_time)))
    ```

-   ***Numerical features***

    ```{r}
    num_col <- colnames(train_df[, sapply(train_df , is.numeric)])
    pander(colnames(train_df[, num_col]))
    ```

    ```{r}
    pander(paste("Number of numerical features " , length(num_col)) , style = "rmarkdown")
    ```

-   ***Categorical features***

    ```{r echo=FALSE, paged.print=TRUE}
    cat_col <- colnames(train_df[ , sapply(train_df , is.character)])
    cat_col <- cat_col[!(cat_col %in% date_time)]
    pander((colnames(train_df[1:5 , cat_col])))
    ```

    ```{r message=FALSE, warning=FALSE, paged.print=FALSE}
    pander(paste("Number of categorical features " , length(cat_col)))
    ```

> # 2. EDA :

In this section we'll walk through some basic *`frequency tables`* and *`summary statistics`* about the data , also we'll explore the *`missing values`* and the spare *`categorical features`*.

## 2.1 Datetime features

-   First convert to Date

    ```{r}
    library(dplyr)

    train_df <- train_df %>%
      mutate_at(vars(date_time), as.Date, format = "%Y-%m-%d")

    pander(str(train_df[,date_time]) , style = "rmarkdown")
    ```

-   Summary for agriculture dates

    ```{r}
    pander(summary(train_df[,date_time]))
    ```

## 2.2 Categorical features

-   Unique values in each categorical column

    ```{r}
    pander(sapply(train_df[,cat_col], function(x) n_distinct(x)) , style = "rmarkdown")

    ```

-   Missing values

    ```{r}
    pander(cat("Number of missing values in categorical columns:",sum(is.na(train_df[,cat_col]))))
    ```

## 2.3 Numerical features

-   Summary of numerical features

    ```{r}
    pander(summary(train_df[num_col] , na.omit = TRUE) , style = "rmarkdown")
    ```

-   Description with some basic statistic (mean, sd and median)

    ```{r}
    pander(describe(train_df[,num_col]  , trim = .15  , na.rm = TRUE)[,3:5],style = "rmarkdown")
    ```

-   Missing values

    ```{r}
    # Filter columns with missing values in num_col
    columns_with_na <- colnames(train_df[,num_col])[colSums(is.na(train_df[,num_col])) > 0]
    pander(sapply(train_df[,columns_with_na], function(x) sum(is.na(x))) , style = "rmarkdown")
    ```

    ```{r}
    pander(paste("Number of missing values in numerical features:"
                 ,sum(is.na(train_df[,num_col]))))
    ```

-   Outliers analysis

    In this analysis we gonna include columns with non missing values , and use the IQR to identify outliers.

    ```{r}
    # Function to check for outliers in a column
    has_outliers <- function(x) {
      Q1 <- quantile(x, 0.25, na.rm = TRUE)
      Q3 <- quantile(x, 0.75, na.rm = TRUE)
      IQR <- Q3 - Q1
      lower_bound <- Q1 - 1.5 * IQR
      upper_bound <- Q3 + 1.5 * IQR
      if (any(x < lower_bound | x > upper_bound, na.rm = TRUE))
      {
        return(colnames(x))
      }
      
    }
    columns_with_outliers <- names(sapply(train_df[,num_col], has_outliers))
    pander(cat("Numbers of coulumns with outliers:" , length(columns_with_outliers)))
    ```

-   Boxplot to show outliers

    ```{r fig.height=10, fig.width=10}
    par(mfrow=c(5, 5))
    for (i in columns_with_outliers) {
      boxplot(train_df[,i], main= i )
    }
    ```

> # 3. Data cleaning and preprocessing:

**In this section we gonna correct some errors in the data , handling missing values and outliers for each variables type.**

## 3.1 Datetime features

we gonna drop date time features because in fact the calender of agriculture is known in these districts.

```{r}
train_df <- train_df[, !names(train_df) %in% date_time]
dim(train_df)
```

## 3.2 Categorical features

**For these variables we'll do the following :**

1.  ***Correct some errors within the District "Jamui" an Block "Gurua" which is "Gaya" Block.***

    ```{r}
    # Group by District and get unique Block values
    unique_blocks <- train_df %>%
      group_by(District) %>%
      summarise(UniqueBlocks = (unique(Block)))

    # Print the resulting data frame
    print(unique_blocks)
    ```

    ```{r}
    train_df[which(train_df$District == 'Jamui' & train_df$Block == 'Gurua'),
             "District"] <- "Gaya"
    ```

<!-- -->

2.  ***Drop columns with more than 10 unique values (this maybe open questions and cause problems in analysis and visualization letter).***

    ```{r}
    get_columns <- function(df, threshold = 10) {
      col_names <- sapply(df, function(col) length(unique(col)) > threshold)
      names(df)[col_names]
    }
    to_drop_cat <- get_columns(train_df[,cat_col])

    train_df <- train_df[, (!names(train_df) %in% to_drop_cat) & 
                           (!names(train_df) %in% date_time)]
    print(dim(train_df))

    ```

    -   Update the cat_col

    ```{r}
    cat_col <- cat_col[!(cat_col %in% to_drop_cat)]
    cat_col
    ```

    ```{r}
    colnames(train_df[])
    ```

## 3.3 Numerical features

**For these variables we'll do the following :**

1.  ***Cutoff some extreme outliers***

    ```{r fig.height=10, fig.width=10}
    train_df <- subset(train_df, 
                 CultLand != 800 &
                 CropCultLand != 800 &
                 SeedlingsPerPit != 442 &
                 !(TransplantingIrrigationHours == 2000.0 |
                     TransplantingIrrigationHours == 1000) &
                 TransIrriCost != 6000.0 &
                 '.1tdUrea' != 120 &
                 '.1appDaysUrea' != 332.0
    )
    par(mfrow=c(5, 5))
    for (i in columns_with_outliers) {
      boxplot(train_df[,i], main= i )
    }
    ```

2.  ***Drop columns with more than 40% of missing values***

    ```{r}
    # Calculate the proportion of missing values in each column
    missing_percent <- colMeans(is.na(train_df[,num_col]))

    # Select columns with more than 40% missing values
    to_drop_num <- names(train_df[,num_col])[missing_percent > 0.4]
    pander(cat("Column Names: \n",to_drop_num))
    # drop the columns
    train_df <- train_df[, ((!names(train_df) %in% to_drop_num)
                            & (!names(train_df) %in% to_drop_cat)
                            & (!names(train_df) %in% date_time))]
    pander(dim(train_df))

    ```

    ```{r}
    num_col <- num_col[(!(num_col %in% to_drop_num) )]
    num_col
    ```

    ```{r}
    # number of misiing after droping
    pander(paste("Number of missing values in numerical features:",
                 sum(is.na(train_df[,num_col]))))
    ```

3.  I**mpute the remaining missing values with median of columns**

    ```{r}
    for (i in 1:ncol(train_df)) {
        train_df[, i][is.na(train_df[, i])] <- median(train_df[, i], na.rm = TRUE)
    }

    # number of misiing after droping
    pander(paste("Number of missing values in numerical features:",
                 sum(is.na(train_df[,num_col]))))             
    ```

> # 4. Data analysis and visualization:

In this section we'll go through to types of analysis ***Univariate analysis** and **Bivariate analysis**.*

## 4.1 ***Univariate analysis***

### 4.1.1 Categorical features

-   District and Block

    ```{r fig.height=5, fig.width=10}
    par(mfrow=c(1,2) ) # divide graph area in 2 columns
    barplot(table(train_df$District),main="Districts",
            xlab="District", ylab="Frequency" ,
            col=c("red" , "green" , 'yellow' , "black"))
    barplot(table(train_df$Block),main="Blocks",
            xlab="Block", ylab="Frequency" , col =  rainbow(length(unique(train_df$Block))))
    ```

-   Methods used in transplantation , harvesting and threshing

    ```{r fig.height=10, fig.width=10}
    par(mfrow=c(2, 2))  # divide graph area in 2 columns
    barplot(table(train_df$Threshing_method),main="Threshing Method",
            xlab="Threshing_method", ylab="Frequency" , col=c("red" , "green"))
    barplot(table(train_df$Harv_method),main="Harvest Method",
            xlab="Harv_method", ylab="Frequency" , col=c("red" , "green"))
    barplot(table(train_df$CropEstMethod),main="Method of transplantation",
            xlab="CropEstMethod", ylab="Frequency", col=c("red" , "green"))

    ```

-   **Transplanting Irrigation Source and Transplanting Irrigation Power Source**

    ```{r fig.height=9, fig.width=12}
    par(mfrow=c(1, 2))  # divide graph area in 2 columns
    barplot(table(train_df$TransplantingIrrigationPowerSource),
            main="Transplanting Irrigation Power Source",
            xlab="TransplantingIrrigationPowerSource", ylab="Frequency" ,
            col = c("red", "green", "yellow"))
    barplot(table(train_df$TransplantingIrrigationSource),
            main="Transplanting Irrigation Source",
            xlab="TransplantingIrrigationSource", ylab="Frequency" ,
             col = c("red", "blue", "green", "yellow", "purple"))
    ```

-   ***Methods of fertilization***

    -   *PCropSolidOrgFertAppMethod : organic fertilizer in your previous crop during land preparation we see that soil applied (تسميد التربة) is the most used, then Broadcasting (رش الأسمدة).*

    -   *MineralFertAppMethod : chemical fertilizer in your current crop during land preparation.*

    -   *MineralFertAppMethod.1 : chemical fertilizer in your current crop during second dose.*

    -   Stubble_use : Management practice of the stubble after harvesting.

    ```{r fig.height=10, fig.width=10}
    par(mfrow=c(2, 2))  # divide graph area in 2 columns
    barplot(table(train_df$PCropSolidOrgFertAppMethod),
            main="Previous Crop Solid Org Fert App Method",
            xlab="PCropSolidOrgFertAppMethod", ylab="Frequency" ,
            col = c("red", "green", "yellow"))
    barplot(table(train_df$MineralFertAppMethod),
            main="Mineral Fert App Method",
            xlab="MineralFertAppMethod", ylab="Frequency" ,
             col = c("red", "blue", "green", "yellow", "purple"))
    barplot(table(train_df$MineralFertAppMethod.1),
            main="Mineral Fert App Method",
            xlab="MineralFertAppMethod.1", ylab="Frequency" ,
             col = c("red", "blue", "green", "yellow", "purple"))
    barplot(table(train_df$Stubble_use),
            main="Stubble use after harvesting",
            xlab="Stubble_use", ylab="Frequency" ,
             col = c("red", "blue", "green", "yellow", "purple"))
    ```

### 4.1.2 Numerical features

-   Distributions of numerical features

    ```{r fig.height=12, fig.width=10}
    par(mfrow=c(5, 2)) 
    for (i in num_col[1:10])
    {
          hist(train_df[,i], 
           main = paste("Histogram of " , i), 
           xlab = i ,
           ylab = "Frequency" ,
           col = c("blue"))
          rug(jitter(train_df[,i]))
          lines(density(train_df[,i]), col="red", lwd=2)
    }
    ```

    ```{r fig.height=12, fig.width=10}
    par(mfrow=c(3, 2)) 
    for (i in num_col[11:16])
    {
          hist(train_df[,i], 
           main = paste("Histogram of " , i), 
           xlab = i ,
           ylab = "Frequency" ,
           col = c("blue"))
          rug(jitter(train_df[,i]))
          lines(density(train_df[,i]), col="red", lwd=2)
    }
    ```

-   **Kernel density plots**

    ***`kernel density estimation is a nonparametric method for estimating the probability density function of a random variable.`***

    ```{r fig.height=12, fig.width=10}
    par(mfrow=c(5, 2)) 
    for (i in num_col[1:10]) {
        d <- density(train_df[,i])
        plot(d, main="Kernel Density of Miles Per Gallon")
        polygon(d, col="red", border="blue")
        rug(train_df[,i], col="brown")
        }
    ```

    ```{r fig.height=8, fig.width=8}
    par(mfrow=c(3, 2)) 
    for (i in num_col[11:16]) {
        d <- density(train_df[,i])
        plot(d, main= paste("Kernel Density of " , i))
        polygon(d, col="red", border="blue")
        rug(train_df[,i], col="brown")
        }
    ```

## 4.2 Bivariante analysis

### 4.2.1 Categorical features

We gonna divide the agriculture Districts to Zones acoording to this [website](https://geography4u.com/wp-content/uploads/2020/06/Agro-climatic-zones-in-Bihar.jpg) .

-   Districts to Zones

    ```{r}
    # Define a function to assign zones based on the District
    assign_value <- function(District) {
      if (District %in% c('Nalanda', 'Gaya')) {
        return('zone1')
      } else if (District == 'Jamui') {
        return('zone2')
      } else if (District == 'Vaishali') {
        return('zone3')
      } else {
        return(NA)  # Handle other cases if needed
      }
    }

    # Apply the function to create a new 'Zone' column
    train_df$Zone <- sapply(train_df$District, assign_value)

    # show the result

    pander(train_df %>%
      group_by(Zone) %>%
      summarise(Unique_Districts = list(unique(District))))

    ```

-   Basic statistics for Yield per Zone

    ```{r}
    pander(train_df %>%
      group_by(Zone) %>%
      summarise(mean = mean(Yield),
                median = median(Yield),
                sum = sum(Yield),
                min = min(Yield),
                max = max(Yield)))
    ```

-   Districts and Blocks

    ```{r}
    pander(train_df %>%
      group_by(District) %>%
      summarise(Unique_Blocks = list(unique(Block))))
    ```

-   Yield per Acre for each Districts

    ```{r}
    train_df$Yield_per_Acre <- train_df$Yield / train_df$Acre 
    pander(train_df %>%
      group_by(District) %>%
      summarise(mean = mean(Yield_per_Acre),
                median = median(Yield_per_Acre),
                sum = sum(Yield_per_Acre),
                min = min(Yield_per_Acre),
                max = max(Yield_per_Acre)))
    ```

### 4.2.2 Numerical features 

-   **Correlation analysis (correlation matrix)**

    ```{r fig.height=10, fig.width=10}
    library(ggcorrplot)
    corr <- round(cor(train_df[,num_col]), 1)

    # Plot
    ggcorrplot(corr,
               type = "lower",
               lab = TRUE, 
               lab_size = 5,  
               colors = c("tomato2", "white", "springgreen3"),
               title="Correlogram of Housing Dataset", 
               ggtheme=theme_bw)
    ```

-   **Scatterplot matrix**

    **we'll select features more than .6 correlation coefficient**

    ```{r}
    cor_matrix <- cor(train_df[,num_col])
    # Find pairs with correlation greater than 0.6
    high_cor_pairs <- which(abs(cor_matrix) > 0.6 & abs(cor_matrix) < 1, arr.ind = TRUE)
    high_cor_pairs <- high_cor_pairs[high_cor_pairs[, 1] < high_cor_pairs[, 2], ]
    high_cor_features <- unique(c(rownames(cor_matrix)[high_cor_pairs[, 1]], colnames(cor_matrix)[high_cor_pairs[, 2]]))

    # Print high correlation pairs
    pander(high_cor_features)

    ```

    ```{r fig.height=10, fig.width=10}
    pairs(~CultLand + BasalDAP + Acre + CropCultLand + Yield, data = train_df ,
           main = "Scatterplot Matrix" , col = c("black"))
    ```

# 5 Statistical testing

***In this section using statistical inferences and hypothesis testing we'll try to answer the questions in The Objective section***.

**NOTE: p-value**: If the p-value is less than the chosen significance level (e.g., 0.05), reject the null hypothesis.

### **1. What the distribution of the yield variables ?**

#### **Kolmogorov-Smirnov Test**

-   ***Hypotheses***

    **Null Hypothesis (H0)**: The sample comes from the Normal distribution.

    **Alternative Hypothesis (H1)**: The sample does not come from the Normal distribution.

    ```{r}
    pander(ks_test <- ks.test(train_df$Yield, "pnorm", mean=mean(train_df$Yield),
                              sd=sd(train_df$Yield)) , style ="grid")
    ```

### 2.what is the crop yield for each District in India  what is the largest?

#### Kruskal-Wallis test

-   ***Hypotheses***

    **Null Hypothesis (H0)**: The distributions of the groups are identical.

    **Alternative Hypothesis (H1)**: At least one of the group distributions is different.

    ```{r}
    pander(train_df %>%
      group_by(District) %>%
      summarise(median = median(Yield)), style ="grid")
    ```

    ```{r}
    # Perform Kruskal-Wallis test
    pander(kruskal.test(Yield ~ District, data = train_df) , style ="grid" )

    ```

### 3.What is the different agriculture methods that influence the crop yield ?

#### Mann-Whitney U Test

-   ***Hypotheses***

    **Null Hypothesis (H0)**: The distributions of the two groups are identical (which implies the medians are equal).

    **Alternative Hypothesis (H1)**: The distributions of the two groups are different (which implies the medians are different).

    ```{r}
    pander(train_df %>%
      group_by(Harv_method ) %>%
      summarise(median = median(Yield)), style ="grid")
    ```

    ```{r}
    pander(wilcox.test(Yield ~ Harv_method, data = train_df) , style ="grid" )
    ```

    ```{r}
    pander(train_df %>%
      group_by(Threshing_method) %>%
      summarise(median = median(Yield)), style ="grid")
    ```

    ```{r}
    pander(wilcox.test(Yield ~ Threshing_method, data = train_df) , style ="grid" )
    ```

### 4.What the best agriculture methods that implies better crop yield ?

#### Mann-Whitney U Test one side

-   ***Hypotheses***

    **Null Hypothesis (H0)**: The distributions of the two groups are identical (which implies the medians are equal).

    **Alternative Hypothesis (H1)**: The values in one group are generally greater than the values in the other group.

    ```{r}
    pander(wilcox.test(Yield ~ Harv_method, alternative = "greater" ,data = train_df)
           , style ="grid") 
    ```

    ```{r}
    pander(wilcox.test(Yield ~ Threshing_method, alternative = "greater" ,data = train_df)
           , style ="grid") 
    ```

### 5.What are the variables that are correlated to the yield variable ?

from section 4.2.2 we have answer the question , but we gonna use the following test for Yield and Acre variables

#### Spearman's Rank Correlation

-   ***Hypotheses***

    **Null Hypothesis (H0)**: There is no association between the two variables.

    **Alternative Hypothesis (H1)**: There is an association between the two variables.

```{r}
pander(cor.test(train_df$Yield, train_df$Acre , method = "spearman"), style ="grid") 
```

-   ***Plot the result***

    ```{r}
    ggplot(train_df, aes(x = Acre, y = Yield)) +
      geom_point() +
      geom_smooth(method = "lm", se = FALSE) +
      labs(title = "Scatter Plot of Yield vs Acre",
           x = "Acre",
           y = "Yield")
    ```

> # 6. Insights and conclusion

***After this long walk through these Indian districts and blocks and saw the nature of rice and wheat agriculture in this zones using this data , i see that this document is obvious from statistical over view, so I'll provide anther Report.pdf document that contain a brief report for all what we explore and draw hypotheses about.***

### Anthor links and references:

-   [github](https://github.com/ahmedalharth/Digital-Green-crop-Yield-Estimate-R-.git).

-   [google drive](https://drive.google.com/drive/folders/18aWIEAIvRfXbyPN4sC2DyuodwvI0_aE4?usp=share_link).
